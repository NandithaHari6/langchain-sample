{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Obtaining dependency information for langchain_groq from https://files.pythonhosted.org/packages/dd/85/425765bc9895f992059a5b893dd6843d795b62b68a78c738a990767c7c87/langchain_groq-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Obtaining dependency information for groq<1,>=0.4.1 from https://files.pythonhosted.org/packages/94/c3/8bf3cd2987e262f9fd45024313dae1d009edaa7a5b429566edfdaedaa024/groq-0.11.0-py3-none-any.whl.metadata\n",
      "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.4,>=0.3 (from langchain_groq)\n",
      "  Obtaining dependency information for langchain-core<0.4,>=0.3 from https://files.pythonhosted.org/packages/30/15/331809ab91c6ee15722dadca6cde3188da16afcbd7a2ef9c60296d00115b/langchain_core-0.3.8-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.3.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hari\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4,>=0.3->langchain_groq)\n",
      "  Obtaining dependency information for langsmith<0.2.0,>=0.1.125 from https://files.pythonhosted.org/packages/87/bd/314a8a1d06d1c576f7246a35eef5ed9322aa6eac8b87095d356bf1a21880/langsmith-0.1.131-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.1.131-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (23.2)\n",
      "Collecting pydantic<3,>=1.9.0 (from groq<1,>=0.4.1->langchain_groq)\n",
      "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "     ---------------------------------------- 0.0/149.4 kB ? eta -:--:--\n",
      "     -------- ------------------------------ 30.7/149.4 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 92.2/149.4 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 149.4/149.4 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3->langchain_groq) (8.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\hari\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hari\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_groq) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (3.9.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (1.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq)\n",
      "  Obtaining dependency information for pydantic-core==2.23.4 from https://files.pythonhosted.org/packages/2f/76/37b7e76c645843ff46c1d73e046207311ef298d3f7b2f7d8f6ac60113071/pydantic_core-2.23.4-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hari\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_groq) (1.26.16)\n",
      "Downloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
      "   ---------------------------------------- 0.0/106.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 106.5/106.5 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.8-py3-none-any.whl (400 kB)\n",
      "   ---------------------------------------- 0.0/400.9 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 112.6/400.9 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 378.9/400.9 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 400.9/400.9 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.131-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 294.6/294.6 kB 17.8 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 434.9/434.9 kB 13.3 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 5.5 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, annotated-types, pydantic, langsmith, groq, langchain-core, langchain_groq\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.8\n",
      "    Uninstalling pydantic-1.10.8:\n",
      "      Successfully uninstalled pydantic-1.10.8\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.31\n",
      "    Uninstalling langsmith-0.1.31:\n",
      "      Successfully uninstalled langsmith-0.1.31\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.33\n",
      "    Uninstalling langchain-core-0.1.33:\n",
      "      Successfully uninstalled langchain-core-0.1.33\n",
      "Successfully installed annotated-types-0.7.0 groq-0.11.0 langchain-core-0.3.8 langchain_groq-0.2.0 langsmith-0.1.131 pydantic-2.9.2 pydantic-core-2.23.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.9.2 which is incompatible.\n",
      "langchain 0.1.13 requires langchain-core<0.2.0,>=0.1.33, but you have langchain-core 0.3.8 which is incompatible.\n",
      "langchain-community 0.0.29 requires langchain-core<0.2.0,>=0.1.33, but you have langchain-core 0.3.8 which is incompatible.\n",
      "langchain-text-splitters 0.0.1 requires langchain-core<0.2.0,>=0.1.28, but you have langchain-core 0.3.8 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain\\n================\\n\\nLangChain is an open-source framework for building applications that leverage large language models (LLMs). It provides a simple and flexible way to integrate LLMs into your application, allowing you to focus on building the logic of your application rather than worrying about the underlying language model.\\n\\nKey Features\\n------------\\n\\n*   **Modular Architecture**: LangChain is designed to be modular, allowing you to easily swap out different language models, databases, and other components as needed.\\n*   **Simple API**: LangChain provides a simple and intuitive API for interacting with language models, making it easy to integrate LLMs into your application.\\n*   **Support for Multiple Language Models**: LangChain supports a wide range of language models, including popular models like LLaMA, T5, and BART.\\n*   **Database Integration**: LangChain provides built-in support for integrating with databases, making it easy to store and retrieve data generated by your application.\\n\\nUse Cases\\n----------\\n\\n*   **Chatbots**: LangChain can be used to build chatbots that can understand and respond to user input.\\n*   **Text Generation**: LangChain can be used to generate text based on a prompt or input.\\n*   **Question Answering**: LangChain can be used to build question answering systems that can answer questions based on a knowledge base or database.\\n\\nExample Code\\n------------\\n\\nHere is an example of how you might use LangChain to build a simple chatbot:\\n```python\\nfrom langchain import LLMChain\\nfrom langchain.llms import LLaMA\\n\\n# Create a new LLaMA model\\nllama = LLaMA(model_name=\"llama-7b\")\\n\\n# Create a new LLMChain instance\\nchain = LLMChain(llama=llama)\\n\\n# Define a function to handle user input\\ndef handle_input(input_text):\\n    # Use the LLMChain to generate a response\\n    response = chain.generate(input_text)\\n    return response\\n\\n# Test the chatbot\\ninput_text = \"Hello, how are you?\"\\nresponse = handle_input(input_text)\\nprint(response)\\n```\\nThis code creates a new LLaMA model and uses it to generate a response to the input text \"Hello, how are you?\".\\n\\nGetting Started\\n---------------\\n\\nTo get started with LangChain, you\\'ll need to install the library using pip:\\n```bash\\npip install langchain\\n```\\nYou\\'ll also need to install a language model, such as LLaMA or T5. You can do this by running the following command:\\n```bash\\npip install transformers\\n```\\nOnce you\\'ve installed the library and a language model, you can start building your application using the LangChain API.\\n\\nConclusion\\n----------\\n\\nLangChain is a powerful framework for building applications that leverage large language models. Its modular architecture, simple API, and support for multiple language models make it an ideal choice for a wide range of applications, from chatbots to text generation and question answering. With LangChain, you can focus on building the logic of your application, rather than worrying about the underlying language model.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 626, 'prompt_tokens': 40, 'total_tokens': 666, 'completion_time': 2.504, 'prompt_time': 0.010402786, 'queue_time': 0.239061324, 'total_time': 2.514402786}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'stop', 'logprobs': None} id='run-922ed87a-031f-4b20-b3b8-2ab36424fdf1-0' usage_metadata={'input_tokens': 40, 'output_tokens': 626, 'total_tokens': 666}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(temperature=0,\n",
    "             groq_api_key=groq_api_key,\n",
    "             model_name=\"llama-3.1-70b-versatile\")\n",
    "res=llm.invoke(\"Tell me about langchain\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "#include<stdio.h>  \n",
      "int main()    \n",
      "{    \n",
      "int n,r,sum=0,temp;    \n",
      "printf(\"enter the number=\");    \n",
      "scanf(\"%d\",&n);    \n",
      "temp=n;    \n",
      "while(n>0)    \n",
      "{    \n",
      "r=n%10;    \n",
      "sum=(sum*10)+r;    \n",
      "n=n/10;    \n",
      "}    \n",
      "if(temp==sum)    \n",
      "printf(\"palindrome number \");    \n",
      "else    \n",
      "printf(\"not palindrome\");   \n",
      "return 0;  \n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code=\"\"\" \n",
    "#include<stdio.h>  \n",
    "int main()    \n",
    "{    \n",
    "int n,r,sum=0,temp;    \n",
    "printf(\"enter the number=\");    \n",
    "scanf(\"%d\",&n);    \n",
    "temp=n;    \n",
    "while(n>0)    \n",
    "{    \n",
    "r=n%10;    \n",
    "sum=(sum*10)+r;    \n",
    "n=n/10;    \n",
    "}    \n",
    "if(temp==sum)    \n",
    "printf(\"palindrome number \");    \n",
    "else    \n",
    "printf(\"not palindrome\");   \n",
    "return 0;  \n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Code Summary**\n",
      "\n",
      "This C program checks whether a given integer is a palindrome or not. A palindrome is a number that remains the same when its digits are reversed.\n",
      "\n",
      "**Functionality**\n",
      "\n",
      "Here's a step-by-step explanation of the code:\n",
      "\n",
      "1. **User Input**: The program prompts the user to enter a number, which is stored in the variable `n`.\n",
      "\n",
      "2. **Temporary Storage**: The input number is copied to a temporary variable `temp` to preserve its original value.\n",
      "\n",
      "3. **Reversal Loop**: The program enters a while loop that continues until all digits of the input number have been processed. In each iteration:\n",
      "   - The remainder of `n` divided by 10 (`n % 10`) is calculated to extract the last digit of the number, which is stored in `r`.\n",
      "   - The extracted digit `r` is appended to the `sum` by shifting its current value one digit to the left (multiplying by 10) and adding `r`.\n",
      "   - The last digit is removed from `n` by performing integer division by 10 (`n / 10`).\n",
      "\n",
      "4. **Palindrome Check**: After the loop, the program checks if the reversed number (`sum`) is equal to the original number (`temp`). If they are equal, the number is a palindrome.\n",
      "\n",
      "5. **Output**: The program prints whether the input number is a palindrome or not.\n",
      "\n",
      "**Example Use Case**\n",
      "\n",
      "If the user enters the number 121, the program will output \"palindrome number\" because 121 is the same when its digits are reversed. If the user enters 123, the program will output \"not palindrome\" because 123 is not the same when its digits are reversed (321).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### This is the code in {language} programming  language:\n",
    "        {code}\n",
    "        ### INSTRUCTION:\n",
    "        Summarize the code in no more than 400 words. Clearly explain the functionality of the code\n",
    "        ### NO PREAMBLE:    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'code':code,'language':\"C\"})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
